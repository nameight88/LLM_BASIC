{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a898547",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f76c",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800c924",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18fd5f",
   "metadata": {},
   "source": [
    "`(3) 벡터저장소 로드`  \n",
    "- 저장해 둔 크로마 벡터저장소를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0562285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소에 저장된 문서 수: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 이전에 사용했던 임베딩 모델을 똑같이 설정을 해준다.\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    ")\n",
    "# ChromaDB에서 저장한것을 가져오기 위해서\n",
    "# Chroma 객체체에서 임베딩,벡터 저장소로 저장한 값들을 가져와야한다.\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"chroma_test\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "print(f\"벡터 저장소에 저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0237e",
   "metadata": {},
   "source": [
    "## 2. LangChain LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db4266",
   "metadata": {},
   "source": [
    "### 2.1 Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6650c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# 다중 메시지 전송\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.3, # 좀더 창의적인 답변을 할 수 있도록 조금 설정을 해준 값\n",
    "    max_tokens=100,\n",
    "    )\n",
    "#튜플 형태로 사용\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "]\n",
    "\n",
    "# 메시지 리스트를 템플릿으로 변환\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 템플릿을 출력\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff39eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query']\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 입력 변수를 출력\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771e1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: 테슬라 창업자는 누구인가요?\n"
     ]
    }
   ],
   "source": [
    "# input 값을 전달하여 프롬프트를 렌더링\n",
    "prompt_text = prompt.format(query=\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 투자자로 참여한 후, CEO로 취임하여 회사를 이끌어왔습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델에 prompt text를 직접 입력\n",
    "response = llm.invoke(prompt_text)\n",
    "\n",
    "# 모델의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27045656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x15c005f70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10979a3c0>, root_client=<openai.OpenAI object at 0x1097ac8f0>, root_async_client=<openai.AsyncOpenAI object at 0x15c005fa0>, model_name='gpt-4o-mini', temperature=0.3, model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "# LCEL 체인을 구성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 체인을 출력\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a65c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'PromptInput',\n",
      " 'type': 'object'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/ly32t5wx3p5b36cvk238t1840000gn/T/ipykernel_18561/995298498.py:3: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  pprint(chain.input_schema.schema())\n"
     ]
    }
   ],
   "source": [
    "# 체인의 입력 스키마를 출력\n",
    "from pprint import pprint\n",
    "pprint(chain.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b371cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하게 되었고, 회사의 비전과 방향성을 주도하게 되었습니다. 따라서 엘론 머스크는\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 1\n",
    "response = chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68e91772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 기여를 하였습니다. 따라서 테슬라의 창립자들 중\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 2\n",
    "response = chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e0da4",
   "metadata": {},
   "source": [
    "### 2.2 Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac6ea",
   "metadata": {},
   "source": [
    "`a) 문자열 파싱 - StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8de35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 기여를 하였습니다. 따라서 테슬라의 창립자들 중', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'length', 'logprobs': None}, id='run-d94890b2-08a1-4055-866b-dfd3dd6c1091-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a73a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 기여를 하였습니다. 따라서 테슬라의 창립자들 중'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StrOutputParser - 문자열 출력을 파싱\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 출력 파서를 실행\n",
    "output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2ab22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리비안(Rivian)은 2009년에 설립되었습니다. 이 회사는 전기차를 개발하고 생산하는 데 주력하고 있으며, 특히 전기 픽업트럭과 SUV 모델로 주목받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "str_chain = prompt | llm  | output_parser\n",
    "\n",
    "query = \"리비안의 설립년도는 언제인가요?\"# 모델에 질문\n",
    "str_response = str_chain.invoke(query)\n",
    "#chain은 프롬프트와 llm만 연결이 되어있는 상태\n",
    "print(str_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea86ac6",
   "metadata": {},
   "source": [
    "`b) JSON 출력 - JsonOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"창업자\": {\\n    \"이름\": \"엘론 머스크\",\\n    \"출생연도\": 1971,\\n    \"국적\": \"미국\",\\n    \"직업\": \"기업가, 엔지니어, 발명가\"\\n  }\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 34, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None} id='run-9d3c1bc5-2047-4f46-952b-129211436b5a-0' usage_metadata={'input_tokens': 34, 'output_tokens': 64, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'창업자': {'이름': '엘론 머스크', '출생연도': 1971, '국적': '미국', '직업': '기업가, 엔지니어, 발명가'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# 체인을 실행 (JSON 출력)\n",
    "json_response = chain.invoke(\"테슬라 창업자는 누구인가요? JSON 형식으로 출력해주세요.\") \n",
    "print(json_response)\n",
    "\n",
    "# 출력 파서를 실행\n",
    "json_parser_output = json_parser.invoke(json_response)\n",
    "print(json_parser_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cf4f",
   "metadata": {},
   "source": [
    "`c) Schema 지정 - PydanticOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60910e31-5146-44f9-ba12-f8412e216bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843d893-5138-4da0-96dc-e45042d4c8bf",
   "metadata": {},
   "source": [
    "## pydantic_v1 버전의 스타일\n",
    "    - v1버전으로 바꿀려면\n",
    "        pip install \"pydantic<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ec0943",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core.pydantic_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticOutputParser\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, validator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#pydantic을 처리 하기 위해서 필요한 객체 BaseModel과 Filed 객체\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pydantic 모델을 생성\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPerson\u001b[39;00m(BaseModel):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.pydantic_v2'"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "#pydantic을 처리 하기 위해서 필요한 객체 BaseModel과 Filed 객체\n",
    "# 24.12.12 강의에서의 버전은 v1버전을 기준으로 설명을 하기 때문에\n",
    "# 나는 v2의 버전을 사용하면서 작성하는 스타일이 변경이 되어서 수정을 해야한다.\n",
    "# Pydantic 모델을 생성\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    title: str = Field(..., description=\"The title or position of the person.\")\n",
    "# 이름과 그 사람의 title이나 직위 2가지 속성을 관리를 하겠다는 설정\n",
    "# 출력 파서를 생성\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person) # 2가지 속성을 관리하겠다는 설정 객체를 전달\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트\")\n",
    "print(\"----------------------------------------\")\n",
    "print(person_parser.get_format_instructions()) # 프롬프트 구조를 직접 전달하는 구조가 format_instructions\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "# Prompt 템플릿을 생성 - Pydantic 모델을 사용\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=person_parser.get_format_instructions())\n",
    "\n",
    "print(\"Prompt 템플릿\")\n",
    "print(\"----------------------------------------\")\n",
    "print(prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066aaf0-9cc3-417c-88f4-09e339efb981",
   "metadata": {},
   "source": [
    "## pydantic_v2버전의 스타일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dad92772-6b1d-448b-a3f4-5da023959fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PydanticOutputParser 프롬프트\n",
      "----------------------------------------\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"examples\": [{\"name\": \"일론 머스크\", \"title\": \"테슬라 CEO\"}], \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"title\": {\"description\": \"The title or position of the person.\", \"title\": \"Title\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "========================================\n",
      "Prompt 템플릿\n",
      "----------------------------------------\n",
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"examples\": [{\"name\": \"일론 머스크\", \"title\": \"테슬라 CEO\"}], \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"title\": {\"description\": \"The title or position of the person.\", \"title\": \"Title\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "Human: 테슬라 창업자는 누구인가요?\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "#pydantic을 처리 하기 위해서 필요한 객체 BaseModel과 Filed 객체\n",
    "# 24.12.12 강의에서의 버전은 v1버전을 기준으로 설명을 하기 때문에\n",
    "# 나는 v2의 버전을 사용하면서 작성하는 스타일이 변경이 되어서 수정을 해야한다.\n",
    "# Pydantic 모델을 생성\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    title: str = Field(..., description=\"The title or position of the person.\")\n",
    "    \n",
    "    model_config = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"name\": \"일론 머스크\",\n",
    "                    \"title\": \"테슬라 CEO\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "# 이름과 그 사람의 title이나 직위 2가지 속성을 관리를 하겠다는 설정\n",
    "# 출력 파서를 생성\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person) # 2가지 속성을 관리하겠다는 설정 객체를 전달\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트\")\n",
    "print(\"----------------------------------------\")\n",
    "print(person_parser.get_format_instructions()) # 프롬프트 구조를 직접 전달하는 구조가 format_instructions\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "# Prompt 템플릿을 생성 - Pydantic 모델을 사용\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=person_parser.get_format_instructions())\n",
    "\n",
    "print(\"Prompt 템플릿\")\n",
    "print(\"----------------------------------------\")\n",
    "print(prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b8a57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='일론 머스크', title='테슬라 CEO')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 구성\n",
    "person_chain = prompt | llm | person_parser\n",
    "\n",
    "# 체인을 실행\n",
    "response = person_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae49f4",
   "metadata": {},
   "source": [
    "## 3. Chat Completion Methods\n",
    "    - invoke -> 완성된 출력을 전달\n",
    "    - stream -> 입력에 대한 응답을 실시간으로 생성되는 토큰을 단어마다 생성하여 출력\n",
    "    - batch -> 입력 리스트에 대한 응답을 배치 단위로 생성하여 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9198b73",
   "metadata": {},
   "source": [
    "`(1) stream`  \n",
    "- 입력에 대한 응답을 실시간 스트림을 생성하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다."
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for chunk in llm.stream(\"테슬라 창업자는 누구인가요?\"):\n",
    "    # 기본적으로 print 함수는 출력을 할 때마다 줄바꿈을 하지만, 줄바꿈 없이 출력하려면 end=\"\"를 사용하면 됩니다.\n",
    "    # flush=True 옵션을 사용하여 출력 버퍼를 즉시 비웁니다. 데이터를 지연 없이 즉시 출력하는 데 유용합니다. 메모리를 효율적으로 출력을 한다.\n",
    "    print(chunk.content, end=\"\", flush=True)  \n",
    "    # time.sleep(0.1)  # 0.1초 대기 (100ms)\n",
    "    # 토큰 단위로 히턴을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01677",
   "metadata": {},
   "source": [
    "`(2) batch`  \n",
    "- 입력 리스트에 대한 응답을 배치 단위로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1477bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 창립자는 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)입니다. 이 두 사람은 2003년에 테슬라 모터스를 설립했습니다. 이후 일론 머스크(Elon Musk)가 2004년에 투자자로 참여하면서 회사의 주요 인물 중 하나가 되었고, 이후 CEO로 취임하여 회사의 성장에 큰 영향을 미쳤습니다.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "리비안(Rivian)의 창업자는 RJ 스칼링(RJ Scaringe)입니다. 그는 2009년에 리비안을 설립하였으며, 전기차 및 친환경 차량 개발에 주력하고 있습니다. 리비안은 전기 픽업트럭인 R1T와 전기 SUV인 R1S를 출시하여 주목받고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"테슬라의 창업자는 누구인가요?\",\n",
    "    \"리비안의 창업자는 누구인가요?\",\n",
    "]\n",
    "\n",
    "responses = llm.batch(questions)\n",
    "\n",
    "for response in responses:\n",
    "    response.pretty_print()\n",
    "    print()\n",
    "#2개의 입력에 대한 배치를 처리를 해서 각각의 응답 배치를 출력을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc16413",
   "metadata": {},
   "source": [
    "## 4. Runnable\n",
    "    - LCEL의 핵심 개념으로 다양한 컴포넌트를 연결하고 실행하는 인터페이스\n",
    "    - 대표적으로 RunnableParallel,RunnablePassthrough,RunnnableLambda가 주로 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734f412",
   "metadata": {},
   "source": [
    "`(1) RunnableParallel`\n",
    "    - 병렬 실행을 담당을 하고 있다.\n",
    "    - 여러 가지를 인터페이스들을 정의를 하고 병렬로 실행이 되어서 각각의 결과를 딕셔너리 형태로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f21024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색기 생성\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 1}, \n",
    ")\n",
    "\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "retrieved_docs_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "pprint(retrieved_docs_text)\n",
    "#한개의 단일 문서를 검색을 했을경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcbc4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.',\n",
       " 'question': '테슬라 창업자는 누구인가요?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# RunnableParrellel 구성\n",
    "runnable = RunnableParallel(\n",
    "    {\"context\": itemgetter(\"context\") , \"question\": itemgetter(\"question\")}\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "runnable = RunnableParallel(\n",
    "    {\"context:llm.invoke(itemgetter(\"context\"))\",\"questiom\":chain.invoke(itmegetter(\"question\"))}\n",
    "\n",
    ")\n",
    "외부의 입력값을 받고 내부에서 한가지의 방식이 아닌 여러가지 방식으로 처리를 할때 사용을 할 수 있다.\n",
    "\"\"\"\n",
    "# 객체를 실행\n",
    "response = runnable.invoke({\"context\": retrieved_docs_text, \"question\": query})\n",
    "\n",
    "# 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb7d0",
   "metadata": {},
   "source": [
    "`(2) RunnablePassthrough` -> 데이터 전달 역할을 보통한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b6495f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': {'query': '테슬라 창업자는 누구인가요?'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# 사용자의 입력값을 있는 그대로 전달을 한다. 여기서 RunnableParallel()메소드를 이용하기 때문에 딕셔너리 형태로 반환되어 나온다.\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "runnable.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458adb6e",
   "metadata": {},
   "source": [
    "`(3) RunnableLambda` -> 데이터 변환을 하는데 보통 쓰인다.\n",
    "- 정의: 파이썬의 커스텀 함수를 매핑하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "509b3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '테슬라 창업자는 누구인가요?', 'word_count': 3}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def count_num_words(text):\n",
    "    return len(text.split())\n",
    "# 값들을 RunnableParallel을 이용해서 한쪽은 RunnablePassthrough메소드에 처리를 하고 한쪽은 RunnableLambda을 이용해서 처리하는 체인으로 구성\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    "    word_count=RunnableLambda(count_num_words),\n",
    ")\n",
    "\n",
    "runnable.invoke(\"테슬라 창업자는 누구인가요?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef9c20-084d-4acb-84ec-74f815727ae5",
   "metadata": {},
   "source": [
    "### Runnable 인터페이스들을 잘 이해를 해야 파이프 라인을 분리하고 다시 합치고 등을 유연하게 반응을해서 시스템을 구현을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7177b",
   "metadata": {},
   "source": [
    "## 5. 전체 RAG 파이프라인 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a953ff",
   "metadata": {},
   "source": [
    "`(1) RAG 프롬프트 템플릿`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c9b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Answer the question based only on the following context.\n",
      "Do not use any external information or knowledge. \n",
      "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
      "\n",
      "[Context]\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "[Question] \n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "[Answer]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt 템플릿을 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿을 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03131d4a",
   "metadata": {},
   "source": [
    "`(2) Retriever Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09b7abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.\\n'\n",
      " '\\n'\n",
      " '2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 '\n",
      " '테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 '\n",
      " '세계 전기차 시장의 약 12.9%를 차지했습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 벡터 검색기\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# 문서 포맷터 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "#하나의 단일 문자열로 결합\n",
    "#리스트 속성으로 돌면서 작동\n",
    "\n",
    "# 체인 구성\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# 체인을 실행\n",
    "response = retriever_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957eeab",
   "metadata": {},
   "source": [
    "`(3) RAG Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d12f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=100)\n",
    "\n",
    "# 체인 생성\n",
    "# 기본적으로 RunnableParallel로 작동이 되고 있다\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2b7fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마틴 에버하드와 마크 타페닝입니다.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9f42",
   "metadata": {},
   "source": [
    "## 6. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57035b9",
   "metadata": {},
   "source": [
    "`(1) invoke 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "990cfb92-7376-4c20-a40d-997f58a1ce44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b207180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:243: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    response = rag_chain.invoke(message)\n",
    "    return response\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82f7a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f970ba",
   "metadata": {},
   "source": [
    "`(2) stream 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40b11b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:243: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "def answer_invoke(message, history):\n",
    "    partial_message = \"\"\n",
    "    for chunk in rag_chain.stream(message):\n",
    "        if chunk is not None:\n",
    "            partial_message = partial_message + chunk\n",
    "            time.sleep(0.1)\n",
    "            yield partial_message\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be3f36e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
